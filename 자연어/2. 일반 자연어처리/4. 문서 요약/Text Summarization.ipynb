{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from newspaper import Article # 파이썬3는 newspaper3k 설치\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 문장을 토큰으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTokenizer(object):\n",
    "\n",
    "    # 초기화\n",
    "    def __init__(self):\n",
    "\n",
    "        self.kkma = Kkma()\n",
    "        self.Okt = Okt()\n",
    "        self.stopwords = [\"아\", \"어\", \"나\", \"너\", \"우리\", \"저희\", \n",
    "                          \"을\", \"를\", \"에\", \"의\", \"은\", \"는\", \"이\", \"가\", \"기자\"]\n",
    "\n",
    "        \n",
    "    # 웹페이지에서 문장 토큰 생성\n",
    "    def url2sentences(self, url):\n",
    "        \n",
    "        # 뉴스 웹페이지를 크롤링\n",
    "        article = Article(url, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        \n",
    "        # 문장 단위로 토큰 추출\n",
    "        sentences = self.kkma.sentences(article.text)\n",
    "        \n",
    "        # 문장의 길이가 짧으면 이전 문장과 통합\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "\n",
    "        return sentences\n",
    "\n",
    "    \n",
    "    # 텍스트에서 문장 토큰 생성\n",
    "    def text2sentences(self, text):\n",
    "        \n",
    "        sentences = self.kkma.sentences(text)\n",
    "        \n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "\n",
    "        return sentences\n",
    "\n",
    "\n",
    "    # 명사를 구함\n",
    "    def get_nouns(self, sentences):\n",
    "\n",
    "        nouns = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if sentence is not '':\n",
    "                # 불용어와 1글자인 단어를 제외하고 명사를 추출\n",
    "                nouns.append(' '.join([noun for noun in self.Okt.nouns(str(sentence))\n",
    "                                        if noun not in self.stopwords and len(noun) > 1]))\n",
    "\n",
    "        return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['동영상 뉴스 [ 앵커] 김대중 정부 때 초고 속 인터넷망의 필요성을 적극 제안했던 인물이지요.',\n",
       " '손정의 일본 소프트 뱅크 회장이 오늘 (4 일) 문 재인 대통령을 만났습니다.',\n",
       " '그는 \" 한국이 집중해야 할 것은 첫째도 AI, 둘째도 AI, 셋째도 AI\"라고 말했습니다.',\n",
       " '인공지능을 말합니다.',\n",
       " '안의 근 기자의 보도입니다.',\n",
       " '[ 기자] 외환 위기 이듬해 1998년, 재일동포 기업인 손정의 소프트 뱅크 회장은 김대중 대통령을 만 나 초고속 인터넷망의 필요성을 조언했습니다.',\n",
       " '노무현 대통령에게는 온라인 게임산업 육성을 제안했습니다.',\n",
       " '문재인 대통령은 오늘 손 회장을 만 나 \" 당시 조언이 한국 경제에 큰 도움이 됐다\" 고 말했습니다.',\n",
       " '손 회장은 \" 대통령은 비전을 갖고 방향을 잡아야 한다 \"며 \" 앞으로 한국이 집중해야 할 건 첫째도 인공지능, 둘째도 인공지능, 셋째도 인공지능\" 이라고 강조했습니다.',\n",
       " '문 대통령은 자금력이 부족한 젊은 혁신 벤처 창업 가들에게 투자해 달라고 당부했습니다.AI',\n",
       " '전문인력 양성에도 지원해 달라고 했고 손 회장은 \" 그렇게 하겠다\" 고 답했습니다.',\n",
       " '일본의 경제 보복 논란이 계속되는 가운데, 문 대통령과 일본 IT 업계를 대표하는 손 회장의 만남 자체는 큰 관심을 받았습니다.',\n",
       " '만남은 예정된 40분을 훌쩍 넘긴 90 분간 진행됐는데 청와대는 \" 일본 경제 보복이나 한일 갈등에 대한 논의는 없었다\" 는 공식 입장을 내놨습니다.',\n",
       " '손 회장은 오늘 저녁 4차 산업 혁신 분야에서 협업 파트너가 될 수 있는 이 재용 삼성전자 부회장과 이해진 네이버 글로벌 투자책임자, 김 택진 엔씨 소프트 대표 등도 만났습니다.',\n",
       " '( 영상 디자인 : 최수진) 안의 근 (egahn @jtbc .co .kr) [ 영상 취재: 주 수영, 이병 구 / 영상 편집: 지 윤 정 ]Copyright by JTBC(http: //jtbc .joins .com) and JTBC Content Hub Co., Ltd. All Rights Reserved. 무단 전재 및 재배포 금지']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenizer = SentenceTokenizer()\n",
    "sentences = sent_tokenizer.url2sentences(\"https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=100&oid=437&aid=0000214234\")\n",
    "sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['동영상 뉴스 앵커 김대중 정부 초고 인터넷 필요성 적극 제안 인물 이지',\n",
       " '손정 일본 소프트 뱅크 회장 오늘 재인 대통령',\n",
       " '한국 집중 첫째 둘째',\n",
       " '인공 지능',\n",
       " '보도',\n",
       " '외환 위기 이듬해 재일동포 기업인 손정 소프트 뱅크 회장 김대중 대통령 고속 인터넷 필요성 조언',\n",
       " '노무현 대통령 온라인 게임 산업 육성 제안',\n",
       " '문재인 대통령 오늘 회장 당시 조언 한국 경제 도움',\n",
       " '회장 대통령 방향 한국 집중 첫째 인공 지능 둘째 인공 지능 인공 지능 강조',\n",
       " '대통령 자금 혁신 창업 투자 달라 당부',\n",
       " '전문 인력 양성 지원 달라 회장',\n",
       " '일본 경제 보복 논란 계속 가운데 대통령 일본 업계 대표 회장 만남 자체 관심',\n",
       " '만남 예정 훌쩍 분간 진행 청와대 일본 경제 보복 한일 갈등 대한 논의 공식 입장',\n",
       " '회장 오늘 저녁 산업 혁신 분야 협업 파트너 삼성 전자 부회장 이해진 네이버 글로벌 투자 책임자 택진 엔씨 소프트 대표',\n",
       " '영상 디자인 최수진 영상 취재 수영 이병 영상 편집 무단 배포 금지']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenizer.get_nouns(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아이 유는 가수이다.', '방탄 소년단은 보이 그룹이다.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenizer.text2sentences(\"아이유는 가수이다. 방탄소년단은 보이그룹이다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 문장 및 단어간의 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatrix(object):\n",
    "\n",
    "    # 초기화\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.tf_idf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "\n",
    "    \n",
    "    # 문장 그래프 생성\n",
    "    def build_sent_graph(self, sentence):\n",
    "        \n",
    "        # TF-IDF 변환\n",
    "        tf_idf_mat = self.tf_idf.fit_transform(sentence).toarray()\n",
    "        \n",
    "        # 모든 문장들을 서로 내적하여 그래프 매트릭스 계산\n",
    "        # 문장이 10개라면 10x10=100개의 항목\n",
    "        graph_sentence = np.dot(tf_idf_mat, tf_idf_mat.T)\n",
    "        \n",
    "        return graph_sentence\n",
    "    \n",
    "    \n",
    "    # 단어 그래프 생성\n",
    "    def build_words_graph(self, sentence):\n",
    "        \n",
    "        # BoW 변환\n",
    "        # normalize() : 0~1 사이로 정규화\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        \n",
    "        # 단어사전 구함\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        \n",
    "        # 모든 단어들을 서로 내적하여 그래프 매트릭스 계산\n",
    "        graph_word = np.dot(cnt_vec_mat.T, cnt_vec_mat)\n",
    "        \n",
    "        # 인덱스-단어 딕셔너리 생성\n",
    "        idx2word = {vocab[word] : word for word in vocab}\n",
    "        \n",
    "        return graph_word, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.50310261],\n",
       "       [0.50310261, 1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_matrix = GraphMatrix()\n",
    "graph_matrix.build_sent_graph([\"나는 인공지능을 좋아해요\", \"나는 딥러닝을 좋아해요\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.        , 0.70710678, 0.70710678, 1.        ],\n",
       "        [0.70710678, 1.        , 0.        , 0.70710678],\n",
       "        [0.70710678, 0.        , 1.        , 0.70710678],\n",
       "        [1.        , 0.70710678, 0.70710678, 1.        ]]),\n",
       " {0: '나는', 2: '인공지능을', 3: '좋아해요', 1: '딥러닝을'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_matrix.build_words_graph([\"나는 인공지능을 좋아해요\", \"나는 딥러닝을 좋아해요\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 텍스트 랭크 알고리즘으로 랭킹 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rank(object):\n",
    "    \n",
    "    # 그래프의 랭킹 점수를 구함\n",
    "    # d : damping factor로 다른 페이지를 클릭할 확률\n",
    "    def get_ranks(self, graph, d=0.85):\n",
    "        \n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        \n",
    "        # 그래프의 노드 개수만큼 반복\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0\n",
    "            link_sum = np.sum(A[:,id])\n",
    "            \n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "                \n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "            \n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B)\n",
    "        \n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '나는', 2: '인공지능을', 3: '좋아해요', 1: '딥러닝을'}\n"
     ]
    }
   ],
   "source": [
    "graph, idx2word = graph_matrix.build_words_graph([\"나는 인공지능을 좋아해요\", \"나는 딥러닝을 좋아해요\"])\n",
    "\n",
    "print(idx2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.2350471902192797,\n",
       " 1: 0.7649528097807199,\n",
       " 2: 0.7649528097807197,\n",
       " 3: 1.2350471902192797}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래프에서 각 노드의 랭킹 점수를 각각 계산\n",
    "rank = Rank()\n",
    "rank.get_ranks(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank(object):\n",
    "    \n",
    "    # 초기화\n",
    "    def __init__(self, text):\n",
    "        \n",
    "        # 문장 토크나이저 설정\n",
    "        self.sent_tokenizer = SentenceTokenizer()\n",
    "        \n",
    "        # URL 또는 텍스트에서 문장 추출\n",
    "        if text[:5] in ('http:', 'https'):\n",
    "            self.sentences = self.sent_tokenizer.url2sentences(text)\n",
    "        else:\n",
    "            self.sentences = self.sent_tokenizer.text2sentences(text)\n",
    "            \n",
    "        # 문장에서 명사만 추출\n",
    "        self.nouns = self.sent_tokenizer.get_nouns(self.sentences)\n",
    "        \n",
    "        # 문장과 단어의 그래프 매트릭스 생성\n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "        \n",
    "        # 그래프 매트릭스로 랭킹 계산\n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "    \n",
    "    \n",
    "    # 문장 요약\n",
    "    def summarize(self, sent_num=3):\n",
    "        \n",
    "        summary = []\n",
    "        index=[]\n",
    "        \n",
    "        # 최대 개수 sent_num 만큼 랭킹 인덱스 추출\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "            \n",
    "        # 인덱스의 순서로 정렬\n",
    "        index.sort()\n",
    "        \n",
    "        # 인덱스에 따른 문장 추가\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "            \n",
    "        return summary\n",
    "\n",
    "\n",
    "    # 키워드 요약\n",
    "    def keywords(self, word_num=10):\n",
    "        \n",
    "        keywords = []\n",
    "        index=[]\n",
    "        \n",
    "        # 최대 개수 word_num 만큼 랭킹 인덱스 추출\n",
    "        for idx in self.sorted_word_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "            \n",
    "        # 인덱스에 따른 단어 추가\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "            \n",
    "        return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손정의 일본 소프트 뱅크 회장이 오늘 (4 일) 문 재인 대통령을 만났습니다.\n",
      "\n",
      "문재인 대통령은 오늘 손 회장을 만 나 \" 당시 조언이 한국 경제에 큰 도움이 됐다\" 고 말했습니다.\n",
      "\n",
      "손 회장은 \" 대통령은 비전을 갖고 방향을 잡아야 한다 \"며 \" 앞으로 한국이 집중해야 할 건 첫째도 인공지능, 둘째도 인공지능, 셋째도 인공지능\" 이라고 강조했습니다.\n",
      "\n",
      "keywords : ['회장', '대통령', '소프트', '대표', '경제', '김대중', '인터넷', '필요성', '산업', '만남']\n"
     ]
    }
   ],
   "source": [
    "url = \"https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=100&oid=437&aid=0000214234\"\n",
    "textrank = TextRank(url)\n",
    "\n",
    "for row in textrank.summarize(3):\n",
    "    print(row)\n",
    "    print()\n",
    "    \n",
    "print('keywords :',textrank.keywords())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
