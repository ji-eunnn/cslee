{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한국', '의', '수도', '는', '서울', '이다']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Okt()  \n",
    "tokens = tokenizer.morphs(\"한국의 수도는 서울이다\")\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'한국': 0, '의': 1, '수도': 2, '는': 3, '서울': 4, '이다': 5}\n"
     ]
    }
   ],
   "source": [
    "# 단어-인덱스 딕셔너리\n",
    "word_to_index = {}\n",
    "\n",
    "# 토큰을 인덱스로 변환\n",
    "for token in tokens:\n",
    "    if token not in word_to_index.keys():\n",
    "        word_to_index[token] = len(word_to_index)\n",
    "        \n",
    "print(word_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫인코딩으로 변환\n",
    "def convert_ohe(word, word_to_index):\n",
    "    \n",
    "    # 벡터를 단어의 개수만큼 0으로 초기화\n",
    "    vector = [0]*(len(word_to_index))\n",
    "    \n",
    "    # 단어의 인덱스 위치에 1 설정\n",
    "    vector[word_to_index[word]] = 1\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_ohe(\"서울\", word_to_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['인공', '지능', '은', '사람', '의', '지능', '을', '기계', '에', '구현', '하였다']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Okt()  \n",
    "text = \"인공지능은 사람의 지능을 기계에 구현하였다\"\n",
    "tokens = tokenizer.morphs(text)\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'인공': 0, '지능': 1, '은': 2, '사람': 3, '의': 4, '을': 5, '기계': 6, '에': 7, '구현': 8, '하였다': 9}\n"
     ]
    }
   ],
   "source": [
    "# 단어-인덱스 딕셔너리\n",
    "word_to_index = {}\n",
    "\n",
    "# 토큰을 인덱스로 변환\n",
    "for token in tokens:\n",
    "    if token not in word_to_index.keys():\n",
    "        word_to_index[token] = len(word_to_index)\n",
    "        \n",
    "print(word_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW로 변환\n",
    "def convert_bow(sentence, word_to_index):\n",
    "    \n",
    "    # 벡터를 단어의 개수만큼 0으로 초기화\n",
    "    vector = [0]*(len(word_to_index))\n",
    "\n",
    "    # 문장을 토큰으로 분리\n",
    "    tokenizer = Okt()\n",
    "    tokens = tokenizer.morphs(sentence)\n",
    "    \n",
    "    # 단어의 인덱스 위치에 1 설정\n",
    "    for token in tokens:\n",
    "        if token in word_to_index.keys():\n",
    "            vector[word_to_index[token]] += 1\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_bow(\"인공지능은 사람의 지능을 기계에 구현하였다\", word_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 0, 1, 1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_bow(\"인공지능은 기계의 지능을 말한다\", word_to_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공 지능 은 사람 의 지능 을 기계 에 구현 하였다\n"
     ]
    }
   ],
   "source": [
    "# 토큰을 문자열로 변환\n",
    "sentence = \" \".join(tokens)\n",
    "\n",
    "print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['인공 지능 은 사람 의 지능 을 기계 에 구현 하였다']\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer의 입력에 맞게 배열로 변경\n",
    "sentences = []\n",
    "sentences.append(sentence)\n",
    "\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'인공': 7, '지능': 8, '은': 4, '사람': 2, '의': 6, '을': 5, '기계': 1, '에': 3, '구현': 0, '하였다': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 빈도수 기반으로 벡터화\n",
    "# 1글자도 인식이 되도록 토큰 패턴 변경\n",
    "cv = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "cv.fit(sentences)\n",
    "\n",
    "print(cv.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer로 변환\n",
    "def convert_cv(sentence, cv):\n",
    "    \n",
    "    # 문장을 토큰으로 분리\n",
    "    tokenizer = Okt()\n",
    "    tokens = tokenizer.morphs(sentence)\n",
    "    \n",
    "    # 토큰을 문자열로 변환\n",
    "    sentence = \" \".join(tokens)\n",
    "    \n",
    "    # CountVectorizer의 입력에 맞게 배열로 변경\n",
    "    sentences = []\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "    # 벡터 변환\n",
    "    vector = cv.transform(sentences).toarray()    \n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_cv(\"인공지능은 사람의 지능을 기계에 구현하였다\", cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1, 1, 1, 2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_cv(\"인공지능은 기계의 지능을 말한다\", cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 3, 'like': 4, 'animals': 0, 'food': 1, 'hate': 2, 'math': 5, 'want': 8, 'to': 7, 'study': 6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"I like animals\",\n",
    "    \"I like food\",\n",
    "    \"I hate math\",\n",
    "    \"I want to study math\",\n",
    "]\n",
    "\n",
    "# TF-IDF로 벡터화\n",
    "# 1글자도 인식이 되도록 토큰 패턴 변경\n",
    "tf_idf = TfidfVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "tf_idf.fit(documents)\n",
    "\n",
    "print(tf_idf.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72664149, 0.        , 0.        , 0.37919167, 0.5728925 ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다른 문서에도 많이 나온 단어는 낮은 수치\n",
    "tf_idf.transform([\"I like animals\"]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90406978, 0.        , 0.        , 0.23589056, 0.3563895 ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 같은 문서에 많이 나온 단어는 높은 수치\n",
    "tf_idf.transform([\"I like animals and love animals\"]).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# TF-IDF로 유사도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45466"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 영화 데이터셋 로드\n",
    "data = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "\n",
       "                               homepage   id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story  862  tt0114709                en   \n",
       "\n",
       "  original_title                                           overview  ...  \\\n",
       "0      Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "\n",
       "  release_date      revenue runtime                          spoken_languages  \\\n",
       "0   1995-10-30  373554033.0    81.0  [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status  tagline      title  video vote_average vote_count  \n",
       "0  Released      NaN  Toy Story  False          7.7     5415.0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 데이터 출력\n",
    "data.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 데이터의 overview 출력\n",
    "# 영화에 대한 설명\n",
    "data.head(1)[\"overview\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터의 일부만 사용\n",
    "data = data.head(10000)\n",
    "\n",
    "# Null인 항목의 개수\n",
    "data[\"overview\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null인 항목을 빈 값으로 대체\n",
    "data[\"overview\"] = data[\"overview\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null인 항목이 없어야 TfidfVectorizer() 가능\n",
    "data[\"overview\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32350)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 변환\n",
    "tf_idf = TfidfVectorizer(stop_words=\"english\")\n",
    "tf_idf_matrix = tf_idf.fit_transform(data[\"overview\"])\n",
    "\n",
    "# 데이터의 개수 : 10000\n",
    "# 단어의 개수 : 32350\n",
    "print(tf_idf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# 1000 x 1000을 서로 내적하여 코사인 유사도를 구함\n",
    "# 각 항목은 두 영화의 유사도를 나타냄\n",
    "cosine_sim = linear_kernel(tf_idf_matrix, tf_idf_matrix)\n",
    "\n",
    "print(cosine_sim.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "Toy Story                      0\n",
      "Jumanji                        1\n",
      "Grumpier Old Men               2\n",
      "Waiting to Exhale              3\n",
      "Father of the Bride Part II    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 중복을 제거하여 영화 제목을 시리즈로 생성\n",
    "indices = pd.Series(data.index, index=data[\"title\"]).drop_duplicates()\n",
    "\n",
    "print(indices.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사한 영화를 구함\n",
    "def get_similar(title, indices, cosine_sim):\n",
    "\n",
    "    # 영화의 인덱스를 구함\n",
    "    try:\n",
    "        index = indices[title]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    # 해당 영화의 유사도를 배열로 변환\n",
    "    # 0 : 인덱스, 1 : 유사도\n",
    "    scores = list(enumerate(cosine_sim[index]))\n",
    "\n",
    "    # 유사도(x[1] 항목)를 기준으로 높은 순으로 정렬\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 가장 유사도가 높은 자신을 제외하고 5개를 추출\n",
    "    scores = scores[1:6]\n",
    "\n",
    "    # 인덱스를 구함\n",
    "    indices = [x[0] for x in scores]\n",
    "\n",
    "    # 각 인덱스의 영화 제목을 구함\n",
    "    titles = data[\"title\"].iloc[indices] \n",
    "    \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2997              Toy Story 2\n",
       "8327                The Champ\n",
       "1071    Rebel Without a Cause\n",
       "3057          Man on the Moon\n",
       "1932                Condorman\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar(\"Toy Story\", indices, cosine_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1154    The Empire Strikes Back\n",
       "1167         Return of the Jedi\n",
       "1267               Mad Dog Time\n",
       "5187        The Triumph of Love\n",
       "309           The Swan Princess\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar(\"Star Wars\", indices, cosine_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
