{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers, losses, metrics\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n"
     ]
    }
   ],
   "source": [
    "# 캐릭터 글자 목록\n",
    "char_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "             'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# 캐릭터 사전 생성\n",
    "char_to_idx = {c: i for i, c in enumerate(char_list)}\n",
    "dic_len = len(char_to_idx)\n",
    "\n",
    "print(char_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 목록\n",
    "# 앞의 세 글자가 주어지면 마지막 글자를 예측\n",
    "# lov -> e\n",
    "word_list = ['love', 'look', 'face', 'fast', 'home', 'hope',\n",
    "             'good', 'gold', 'tree', 'true', 'road', 'rock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 데이터 생성\n",
    "def make_batch(word_list):\n",
    "    \n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for word in word_list:\n",
    "        # 입력 단어를 인덱스로 변환\n",
    "        input = [char_to_idx[c] for c in word[:-1]]\n",
    "        \n",
    "        # 목표 캐릭터를 인덱스로 변환\n",
    "        target = char_to_idx[word[-1]]\n",
    "\n",
    "        # 입력 인덱스를 원핫인코딩으로 변환\n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "\n",
    "        # 목표 인덱스를 원핫인코딩으로 변환\n",
    "        target_batch.append(np.eye(dic_len)[target])\n",
    "\n",
    "    return np.array(input_batch), np.array(target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력/목표 배치 생성\n",
    "x_train, y_train = make_batch(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 글자만큼 타임스텝 반복\n",
    "time_step = 3\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(64, input_shape = (time_step, dic_len)))\n",
    "    model.add(layers.Dense(dic_len, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 훈련 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 3.2398 - acc: 0.0833\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1561 - acc: 0.4167\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0804 - acc: 0.5000\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9902 - acc: 0.6667\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8739 - acc: 0.6667\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7218 - acc: 0.6667\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.5181 - acc: 0.5833\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2526 - acc: 0.5833\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.9450 - acc: 0.5000\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.6510 - acc: 0.5000\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4297 - acc: 0.5000\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.2945 - acc: 0.5000\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.2099 - acc: 0.5000\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.1468 - acc: 0.5000\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.1000 - acc: 0.5000\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.0587 - acc: 0.5833\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.0186 - acc: 0.5833\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.9775 - acc: 0.6667\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.9447 - acc: 0.6667\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.9047 - acc: 0.6667\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.8669 - acc: 0.6667\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.8271 - acc: 0.6667\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7938 - acc: 0.6667\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7507 - acc: 0.6667\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7174 - acc: 0.7500\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6816 - acc: 0.7500\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6479 - acc: 0.7500\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6157 - acc: 0.6667\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5821 - acc: 0.7500\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5552 - acc: 0.7500\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5239 - acc: 0.7500\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4987 - acc: 0.7500\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4760 - acc: 0.7500\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4523 - acc: 0.7500\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4305 - acc: 0.7500\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4124 - acc: 0.8333\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3928 - acc: 0.9167\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - acc: 0.9167\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3628 - acc: 0.8333\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3447 - acc: 0.9167\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3307 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3170 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3092 - acc: 0.9167\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2981 - acc: 0.8333\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2848 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2757 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2691 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2607 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2530 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2384 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2344 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2277 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2198 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2133 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2100 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2024 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1930 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1918 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1810 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1781 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1709 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1669 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1630 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1579 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1531 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1455 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1459 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1338 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1333 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1272 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1258 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1185 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1173 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1094 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1064 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0935 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0927 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0860 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0856 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0813 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0765 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0745 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0698 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0661 - acc: 1.0000\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0639 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0628 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0580 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0513 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0469 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0461 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0426 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0393 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0323 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a15ac8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = build_model()\n",
    "\n",
    "# 훈련 시작\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.15593610e-09, 3.92362542e-09, 3.39198358e-09, 5.97915961e-04,\n",
       "        9.74902153e-01, 2.03824646e-09, 2.68940803e-09, 2.76509993e-09,\n",
       "        1.57705782e-09, 2.68146860e-09, 2.40238272e-02, 2.29818409e-09,\n",
       "        3.51762530e-09, 4.13557588e-09, 6.52650778e-09, 3.00624303e-09,\n",
       "        2.36155895e-09, 1.50774948e-09, 4.24983693e-09, 4.76046873e-04,\n",
       "        1.38333534e-09, 2.31604114e-09, 2.56572252e-09, 1.82073034e-09,\n",
       "        3.97753119e-09, 8.84318618e-10],\n",
       "       [7.46743201e-09, 1.86082794e-08, 2.81349610e-08, 1.10401930e-02,\n",
       "        4.24866937e-02, 8.58319904e-09, 2.28888357e-08, 2.38146090e-08,\n",
       "        1.19482735e-08, 3.02524192e-08, 9.45788741e-01, 2.35798030e-08,\n",
       "        1.80306721e-08, 1.87187030e-08, 2.95103924e-08, 2.82794712e-08,\n",
       "        1.89037674e-08, 1.26891386e-08, 1.86165874e-08, 6.84256607e-04,\n",
       "        1.20268808e-08, 1.85807583e-08, 1.90239273e-08, 1.24103821e-08,\n",
       "        2.17478977e-08, 1.80600992e-08],\n",
       "       [2.60268482e-08, 5.58085418e-08, 4.70681627e-08, 1.07332919e-04,\n",
       "        9.69015896e-01, 2.12766373e-08, 2.79945098e-08, 3.54759599e-08,\n",
       "        2.38193429e-08, 2.94249674e-08, 2.96172616e-03, 2.44124010e-08,\n",
       "        6.76266865e-08, 4.48380355e-08, 8.65722711e-08, 3.06244523e-08,\n",
       "        3.00912362e-08, 1.71803993e-08, 3.65162514e-08, 2.79146973e-02,\n",
       "        1.90036964e-08, 2.91020239e-08, 2.72062781e-08, 2.56293031e-08,\n",
       "        4.11980743e-08, 1.49927288e-08],\n",
       "       [6.51067580e-07, 7.09336916e-07, 1.56527142e-06, 2.69585289e-04,\n",
       "        2.27877758e-02, 3.70069586e-07, 9.18074420e-07, 8.74907357e-07,\n",
       "        1.14198690e-06, 7.96215659e-07, 8.40834342e-04, 5.96914958e-07,\n",
       "        2.60134607e-06, 8.39878169e-07, 1.66007180e-06, 1.24588462e-06,\n",
       "        5.60620265e-07, 3.80563762e-07, 6.22029006e-07, 9.76081014e-01,\n",
       "        6.88688203e-07, 1.18662945e-06, 1.03410468e-06, 9.70495876e-07,\n",
       "        6.79503785e-07, 7.09042013e-07],\n",
       "       [1.05345745e-13, 3.02287438e-13, 1.12402926e-13, 9.25406880e-08,\n",
       "        9.99992609e-01, 1.01061439e-13, 6.71013199e-14, 9.14655856e-14,\n",
       "        3.87469191e-14, 4.17130557e-14, 4.71862541e-06, 3.67835001e-14,\n",
       "        2.27336203e-13, 2.91523777e-13, 2.24449081e-13, 6.04087228e-14,\n",
       "        6.32109111e-14, 3.07437893e-14, 3.01309433e-13, 2.54510928e-06,\n",
       "        2.69085613e-14, 8.53928202e-14, 6.28482116e-14, 4.69767827e-14,\n",
       "        2.20783529e-13, 8.17747545e-15],\n",
       "       [1.15930201e-13, 3.19091379e-13, 1.24370918e-13, 9.17229528e-08,\n",
       "        9.99991775e-01, 1.10437951e-13, 8.01043937e-14, 1.06173920e-13,\n",
       "        4.06038355e-14, 4.73042931e-14, 5.13621535e-06, 4.09497807e-14,\n",
       "        2.45526743e-13, 3.13013314e-13, 2.49006788e-13, 6.87777404e-14,\n",
       "        6.98770875e-14, 3.42980005e-14, 3.51140476e-13, 2.97438555e-06,\n",
       "        2.96788215e-14, 9.17827012e-14, 7.32408993e-14, 5.11882508e-14,\n",
       "        2.44212934e-13, 9.68730406e-15],\n",
       "       [1.43587879e-08, 6.86782675e-09, 1.23318378e-08, 9.99800742e-01,\n",
       "        6.74260718e-07, 1.07183178e-08, 1.14604513e-08, 1.37972069e-08,\n",
       "        1.86556601e-08, 4.59740468e-09, 1.98280206e-04, 3.70235020e-09,\n",
       "        1.95951291e-08, 9.28485200e-09, 1.43971812e-08, 1.82548821e-08,\n",
       "        3.11929726e-09, 5.75637138e-09, 9.08070774e-09, 1.85309958e-07,\n",
       "        1.18292540e-08, 1.39005669e-08, 1.18961365e-08, 1.30442102e-08,\n",
       "        9.30353572e-09, 6.99444502e-09],\n",
       "       [9.15834253e-09, 3.68649755e-09, 6.57921717e-09, 9.99860406e-01,\n",
       "        9.92731316e-07, 6.73369716e-09, 6.52649801e-09, 7.56074048e-09,\n",
       "        9.95692329e-09, 2.47665954e-09, 1.38549032e-04, 2.05477035e-09,\n",
       "        1.15718430e-08, 4.89548269e-09, 8.59569216e-09, 9.52451362e-09,\n",
       "        1.68603198e-09, 3.36440120e-09, 5.47302648e-09, 1.55585909e-07,\n",
       "        6.91153712e-09, 7.83055754e-09, 6.45661657e-09, 6.99515601e-09,\n",
       "        4.75689843e-09, 3.74539466e-09],\n",
       "       [6.51044838e-14, 1.65613982e-13, 6.86207073e-14, 9.41464009e-08,\n",
       "        9.99994755e-01, 6.03048969e-14, 3.52258912e-14, 5.31659305e-14,\n",
       "        2.26077397e-14, 2.12376012e-14, 3.20910203e-06, 2.01688912e-14,\n",
       "        1.40289608e-13, 1.70780558e-13, 1.43535954e-13, 3.42481577e-14,\n",
       "        3.27425837e-14, 1.68806280e-14, 1.73535489e-13, 1.85937336e-06,\n",
       "        1.41610602e-14, 4.58863023e-14, 3.43283378e-14, 2.75699179e-14,\n",
       "        1.27720534e-13, 4.09402745e-15],\n",
       "       [8.98879698e-14, 2.39924942e-13, 8.50521300e-14, 8.67277521e-08,\n",
       "        9.99994636e-01, 8.11645876e-14, 5.10799424e-14, 7.10722578e-14,\n",
       "        2.94020315e-14, 3.07556986e-14, 3.31337947e-06, 2.71372551e-14,\n",
       "        1.89071428e-13, 2.23786945e-13, 1.86327001e-13, 4.56872699e-14,\n",
       "        4.56718471e-14, 2.34951930e-14, 2.43048203e-13, 1.96231508e-06,\n",
       "        2.02461661e-14, 6.34764797e-14, 4.76690796e-14, 3.56822048e-14,\n",
       "        1.71351526e-13, 5.79713965e-15],\n",
       "       [1.62932650e-07, 1.26606551e-07, 2.03058761e-07, 9.42712665e-01,\n",
       "        8.51681631e-04, 1.48542981e-07, 1.63337603e-07, 2.06603147e-07,\n",
       "        1.93861496e-07, 1.35950827e-07, 5.63499629e-02, 9.95232341e-08,\n",
       "        2.31684652e-07, 1.22366885e-07, 2.83412334e-07, 2.36112541e-07,\n",
       "        8.75903936e-08, 1.15984641e-07, 1.46831439e-07, 8.20975256e-05,\n",
       "        1.43659250e-07, 1.81518686e-07, 1.76532097e-07, 1.47067297e-07,\n",
       "        1.37705484e-07, 9.52734354e-08],\n",
       "       [8.30032079e-08, 1.43235440e-07, 1.44310945e-07, 8.22969899e-02,\n",
       "        5.94661757e-03, 9.41637310e-08, 1.81660511e-07, 1.87970855e-07,\n",
       "        1.04329800e-07, 1.68774520e-07, 9.11662102e-01, 1.53218195e-07,\n",
       "        1.01537367e-07, 1.22580985e-07, 1.72563148e-07, 1.50320901e-07,\n",
       "        1.29935415e-07, 1.15072936e-07, 1.55954027e-07, 9.15396813e-05,\n",
       "        8.55371241e-08, 1.18614153e-07, 1.43762591e-07, 1.03648489e-07,\n",
       "        1.40865581e-07, 1.08113802e-07]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련셋 데이터 예측\n",
    "# 26개 캐릭터의 원핫인코딩 형식\n",
    "results = model.predict(x_train)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10,  4, 19,  4,  4,  3,  3,  4,  4,  3, 10], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1축을 기준으로 최대값의 인덱스 구함\n",
    "results = np.argmax(results, 1) \n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lov -> love\n",
      "loo -> look\n",
      "fac -> face\n",
      "fas -> fast\n",
      "hom -> home\n",
      "hop -> hope\n",
      "goo -> good\n",
      "gol -> gold\n",
      "tre -> tree\n",
      "tru -> true\n",
      "roa -> road\n",
      "roc -> rock\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과 출력\n",
    "for i, word in enumerate(word_list):\n",
    "    last_char = char_list[results[i]]\n",
    "    print(word[:3] + ' -> ' + word[:3] + last_char)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
